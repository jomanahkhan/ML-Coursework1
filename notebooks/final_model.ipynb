{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCJ71BS6R245"
      },
      "source": [
        "install required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIOCFURoPrRl",
        "outputId": "8620ed7d-7f84-41d5-bb7f-bd73e698c363"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.38)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.2.1-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.9 alembic-1.14.1 colorlog-6.9.0 optuna-4.2.1\n",
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.11/dist-packages (13.3.0)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x) (1.26.4)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x) (0.8.3)\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install scikit-learn\n",
        "!pip install optuna\n",
        "!pip install -U cupy-cuda12x\n",
        "!pip install catboost -U"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHUBBYCgSU_e"
      },
      "source": [
        "load the data, encode categorical features, and add more features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nz3C-DxGRQu-",
        "outputId": "ec8679f7-528c-448c-9548-2e2b2ae893ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 35 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   outcome        10000 non-null  float64\n",
            " 1   carat          10000 non-null  float64\n",
            " 2   cut            10000 non-null  int64  \n",
            " 3   color          10000 non-null  int64  \n",
            " 4   clarity        10000 non-null  int64  \n",
            " 5   depth          10000 non-null  float64\n",
            " 6   table          10000 non-null  float64\n",
            " 7   price          10000 non-null  int64  \n",
            " 8   x              10000 non-null  float64\n",
            " 9   y              10000 non-null  float64\n",
            " 10  z              10000 non-null  float64\n",
            " 11  a1             10000 non-null  float64\n",
            " 12  a2             10000 non-null  float64\n",
            " 13  a3             10000 non-null  float64\n",
            " 14  a4             10000 non-null  float64\n",
            " 15  a5             10000 non-null  float64\n",
            " 16  b1             10000 non-null  float64\n",
            " 17  b2             10000 non-null  float64\n",
            " 18  b3             10000 non-null  float64\n",
            " 19  b4             10000 non-null  float64\n",
            " 20  b5             10000 non-null  float64\n",
            " 21  a6             10000 non-null  float64\n",
            " 22  a7             10000 non-null  float64\n",
            " 23  a8             10000 non-null  float64\n",
            " 24  a9             10000 non-null  float64\n",
            " 25  a10            10000 non-null  float64\n",
            " 26  b6             10000 non-null  float64\n",
            " 27  b7             10000 non-null  float64\n",
            " 28  b8             10000 non-null  float64\n",
            " 29  b9             10000 non-null  float64\n",
            " 30  b10            10000 non-null  float64\n",
            " 31  carat_log      10000 non-null  float64\n",
            " 32  price_log      10000 non-null  float64\n",
            " 33  depth_x_table  10000 non-null  float64\n",
            " 34  depth_x_carat  10000 non-null  float64\n",
            "dtypes: float64(31), int64(4)\n",
            "memory usage: 2.7 MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\"\"\"\n",
        "uncomment to load the data from google drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "train_file_path = \"/content/drive/My Drive/MLCW1/CW1_train.csv\"\n",
        "\"\"\"\n",
        "train_file_path = \"/data/CW1_train.csv\"\n",
        "df = pd.read_csv(train_file_path)\n",
        "\n",
        "\n",
        "# Define the ordinal encoding for each categorical feature\n",
        "cut_order = [\"Fair\", \"Good\", \"Very Good\", \"Premium\", \"Ideal\"] #Ideal is the best\n",
        "color_order = [\"J\", \"I\", \"H\", \"G\", \"F\", \"E\", \"D\"]  # D is the best, J is the worst\n",
        "clarity_order = [\"I1\", \"SI2\", \"SI1\", \"VS2\", \"VS1\", \"VVS2\", \"VVS1\", \"IF\"]  # IF is the best\n",
        "\n",
        "# Create a mapping dictionary for encoding\n",
        "cut_mapping = {cut: i for i, cut in enumerate(cut_order)}\n",
        "color_mapping = {color: i for i, color in enumerate(color_order)}\n",
        "clarity_mapping = {clarity: i for i, clarity in enumerate(clarity_order)}\n",
        "\n",
        "# Apply the encoding to the dataframe\n",
        "df_encoded = df.copy()\n",
        "df_encoded[\"cut\"] = df_encoded[\"cut\"].map(cut_mapping)\n",
        "df_encoded[\"color\"] = df_encoded[\"color\"].map(color_mapping)\n",
        "df_encoded[\"clarity\"] = df_encoded[\"clarity\"].map(clarity_mapping)\n",
        "\n",
        "#Feature Engineering:\n",
        "#log transformations for skewed distributions.\n",
        "df_encoded[\"carat_log\"] = np.log1p(df_encoded[\"carat\"])\n",
        "df_encoded[\"price_log\"] = np.log1p(df_encoded[\"price\"])\n",
        "df_encoded[\"depth_x_table\"] = df_encoded[\"depth\"] * df_encoded[\"table\"]\n",
        "df_encoded[\"depth_x_carat\"] = df_encoded[\"depth\"] * df_encoded[\"carat\"]\n",
        "\n",
        "print(df_encoded.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_p6dxepLSnx"
      },
      "source": [
        "train final model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9E81fnUCOyG",
        "outputId": "ce50e660-06d7-4f29-a60d-1c6557495e70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Training R² Score: 0.51590\n",
            "✅ Validation (Test) R² Score: 0.46709\n",
            "✅ Training MSE: 78.20365\n",
            "✅ Validation (Test) MSE: 86.86698\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Define feature set\n",
        "a_b_features = [f\"a{i}\" for i in range(1, 6)] + [f\"b{i}\" for i in range(1, 6)]\n",
        "selected_features = [\"carat\", \"depth\", \"table\", \"x\", \"y\",\n",
        "                     \"depth_x_table\", \"depth_x_carat\", \"carat_log\", \"price_log\"] + a_b_features + [\"cut\", \"color\", \"clarity\"]\n",
        "\n",
        "# Load data (Ensure df_encoded is defined before running)\n",
        "X = df_encoded[selected_features]\n",
        "y = df_encoded[\"outcome\"]\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define CatBoost model parameters\n",
        "best_catboost_params = {\n",
        "     \"iterations\": 4284,\n",
        "    \"depth\": 2, #reduced depth from 3 to 2 to reduce overfitting and it worked.\n",
        "    \"learning_rate\": 0.017181970020733888,\n",
        "    \"l2_leaf_reg\": 1.23,\n",
        "    \"border_count\": 173,\n",
        "    \"random_strength\": 1.5232946917610097,\n",
        "    \"task_type\": \"GPU\",  # Use GPU acceleration\n",
        "    \"loss_function\": \"RMSE\",\n",
        "    \"random_seed\": 42,  # Fix randomness\n",
        "    \"verbose\": 100,\n",
        "    \"use_best_model\": True  # Use best iteration from training\n",
        "}\n",
        "\n",
        "# Train model on training set\n",
        "model = CatBoostRegressor(**best_catboost_params)\n",
        "model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=0)\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "# Compute R² scores\n",
        "r2_train = r2_score(y_train, y_train_pred)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "# Compute Mean Squared Error (MSE)\n",
        "mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "# Print results\n",
        "print(f\"✅ Training R² Score: {r2_train:.5f}\")\n",
        "print(f\"✅ Validation (Test) R² Score: {r2_test:.5f}\")\n",
        "print(f\"✅ Training MSE: {mse_train:.5f}\")\n",
        "print(f\"✅ Validation (Test) MSE: {mse_test:.5f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeDchScQUbIB"
      },
      "source": [
        "make predictions on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "JQBWpCtmUaWS",
        "outputId": "12ac7ba1-7d9f-4653-eb82-4ecf62b59199"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 22 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   carat          1000 non-null   float64\n",
            " 1   depth          1000 non-null   float64\n",
            " 2   table          1000 non-null   float64\n",
            " 3   x              1000 non-null   float64\n",
            " 4   y              1000 non-null   float64\n",
            " 5   depth_x_table  1000 non-null   float64\n",
            " 6   depth_x_carat  1000 non-null   float64\n",
            " 7   carat_log      1000 non-null   float64\n",
            " 8   price_log      1000 non-null   float64\n",
            " 9   a1             1000 non-null   float64\n",
            " 10  a2             1000 non-null   float64\n",
            " 11  a3             1000 non-null   float64\n",
            " 12  a4             1000 non-null   float64\n",
            " 13  a5             1000 non-null   float64\n",
            " 14  b1             1000 non-null   float64\n",
            " 15  b2             1000 non-null   float64\n",
            " 16  b3             1000 non-null   float64\n",
            " 17  b4             1000 non-null   float64\n",
            " 18  b5             1000 non-null   float64\n",
            " 19  cut            1000 non-null   int64  \n",
            " 20  color          1000 non-null   int64  \n",
            " 21  clarity        1000 non-null   int64  \n",
            "dtypes: float64(19), int64(3)\n",
            "memory usage: 172.0 KB\n",
            "None\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_dd3b6d21-ef92-4578-8523-4743af43832c\", \"CW1_submission_k21172604.csv\", 19097)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Load data\n",
        "'''\n",
        "uncomment to load test data from google drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "test_file_path = \"/content/drive/My Drive/MLCW1/CW1_test.csv\"\n",
        "'''\n",
        "test_file_path = \"/data/CW1_train.csv\"\n",
        "\n",
        "X_test = pd.read_csv(test_file_path)\n",
        "\n",
        "# Apply the same categorical encoding\n",
        "X_test[\"cut\"] = X_test[\"cut\"].map(cut_mapping)\n",
        "X_test[\"color\"] = X_test[\"color\"].map(color_mapping)\n",
        "X_test[\"clarity\"] = X_test[\"clarity\"].map(clarity_mapping)\n",
        "\n",
        "# Apply the same feature engineering\n",
        "X_test[\"carat_log\"] = np.log1p(X_test[\"carat\"])\n",
        "X_test[\"price_log\"] = np.log1p(X_test[\"price\"]) \n",
        "X_test[\"depth_x_table\"] = X_test[\"depth\"] * X_test[\"table\"]\n",
        "X_test[\"depth_x_carat\"] = X_test[\"depth\"] * X_test[\"carat\"]\n",
        "\n",
        "# Ensure feature alignment (order & missing columns)\n",
        "X_test = X_test[selected_features]  # Ensure same features as training\n",
        "print(X_test.info())\n",
        "# Predict test outcomes\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Save predictions in required format\n",
        "submission = pd.DataFrame({'yhat': predictions})\n",
        "\n",
        "submission_filename = \"CW1_submission_k21172604.csv\" \n",
        "\n",
        "# Save the file locally\n",
        "submission.to_csv(submission_filename, index=False)\n",
        "\n",
        "print(f\"✅ Submission file saved as: {submission_filename}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

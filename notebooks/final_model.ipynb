{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCJ71BS6R245"
      },
      "source": [
        "install required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIOCFURoPrRl",
        "outputId": "b933ca09-41f5-41d8-8d10-22122c5024ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.2.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.14.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.38)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.9)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Requirement already satisfied: cupy-cuda12x in /usr/local/lib/python3.11/dist-packages (13.3.0)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x) (1.26.4)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.11/dist-packages (from cupy-cuda12x) (0.8.3)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.7)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install scikit-learn\n",
        "!pip install optuna\n",
        "!pip install -U cupy-cuda12x\n",
        "!pip install catboost -U"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHUBBYCgSU_e"
      },
      "source": [
        "load the data, encode categorical features, and add more features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nz3C-DxGRQu-",
        "outputId": "d26f5fd7-788b-474f-817c-81988f23fc5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 35 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   outcome        10000 non-null  float64\n",
            " 1   carat          10000 non-null  float64\n",
            " 2   cut            10000 non-null  int64  \n",
            " 3   color          10000 non-null  int64  \n",
            " 4   clarity        10000 non-null  int64  \n",
            " 5   depth          10000 non-null  float64\n",
            " 6   table          10000 non-null  float64\n",
            " 7   price          10000 non-null  int64  \n",
            " 8   x              10000 non-null  float64\n",
            " 9   y              10000 non-null  float64\n",
            " 10  z              10000 non-null  float64\n",
            " 11  a1             10000 non-null  float64\n",
            " 12  a2             10000 non-null  float64\n",
            " 13  a3             10000 non-null  float64\n",
            " 14  a4             10000 non-null  float64\n",
            " 15  a5             10000 non-null  float64\n",
            " 16  b1             10000 non-null  float64\n",
            " 17  b2             10000 non-null  float64\n",
            " 18  b3             10000 non-null  float64\n",
            " 19  b4             10000 non-null  float64\n",
            " 20  b5             10000 non-null  float64\n",
            " 21  a6             10000 non-null  float64\n",
            " 22  a7             10000 non-null  float64\n",
            " 23  a8             10000 non-null  float64\n",
            " 24  a9             10000 non-null  float64\n",
            " 25  a10            10000 non-null  float64\n",
            " 26  b6             10000 non-null  float64\n",
            " 27  b7             10000 non-null  float64\n",
            " 28  b8             10000 non-null  float64\n",
            " 29  b9             10000 non-null  float64\n",
            " 30  b10            10000 non-null  float64\n",
            " 31  carat_log      10000 non-null  float64\n",
            " 32  price_log      10000 non-null  float64\n",
            " 33  depth_x_table  10000 non-null  float64\n",
            " 34  depth_x_carat  10000 non-null  float64\n",
            "dtypes: float64(31), int64(4)\n",
            "memory usage: 2.7 MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\"\"\"\n",
        "uncomment to load the data from google drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "train_file_path = \"/content/drive/My Drive/MLCW1/CW1_train.csv\"\n",
        "\"\"\"\n",
        "train_file_path = \"/data/CW1_train.csv\"\n",
        "df = pd.read_csv(train_file_path)\n",
        "\n",
        "# Define the ordinal encoding for each categorical feature\n",
        "cut_order = [\"Fair\", \"Good\", \"Very Good\", \"Premium\", \"Ideal\"] #Ideal is the best\n",
        "color_order = [\"J\", \"I\", \"H\", \"G\", \"F\", \"E\", \"D\"]  # D is the best, J is the worst\n",
        "clarity_order = [\"I1\", \"SI2\", \"SI1\", \"VS2\", \"VS1\", \"VVS2\", \"VVS1\", \"IF\"]  # IF is the best\n",
        "\n",
        "# Create a mapping dictionary for encoding\n",
        "cut_mapping = {cut: i for i, cut in enumerate(cut_order)}\n",
        "color_mapping = {color: i for i, color in enumerate(color_order)}\n",
        "clarity_mapping = {clarity: i for i, clarity in enumerate(clarity_order)}\n",
        "\n",
        "# Apply the encoding to the dataframe\n",
        "df_encoded = df.copy()\n",
        "df_encoded[\"cut\"] = df_encoded[\"cut\"].map(cut_mapping)\n",
        "df_encoded[\"color\"] = df_encoded[\"color\"].map(color_mapping)\n",
        "df_encoded[\"clarity\"] = df_encoded[\"clarity\"].map(clarity_mapping)\n",
        "\n",
        "#Feature Engineering:\n",
        "#log transformations for skewed distributions.\n",
        "df_encoded[\"carat_log\"] = np.log1p(df_encoded[\"carat\"])\n",
        "df_encoded[\"price_log\"] = np.log1p(df_encoded[\"price\"])\n",
        "df_encoded[\"depth_x_table\"] = df_encoded[\"depth\"] * df_encoded[\"table\"]\n",
        "df_encoded[\"depth_x_carat\"] = df_encoded[\"depth\"] * df_encoded[\"carat\"]\n",
        "\n",
        "print(df_encoded.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92EVEtpmSfqR"
      },
      "source": [
        "train final model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KzTj3FsRi5M",
        "outputId": "7de28576-4e19-44b6-dd13-a7e52b8d9d76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Cross-Validated Model R² Score: 0.48188 \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Keep `a1-a5, b1-b5` (since they rank high in the random forest analysis and correlation matrix)\n",
        "a_b_features = [f\"a{i}\" for i in range(1, 6)] + [f\"b{i}\" for i in range(1, 6)]\n",
        "\n",
        "# Final feature set: numerical + interactions + binned price + binned carat + `a1-b5` + encoded categorical\n",
        "selected_features = [\"carat\", \"depth\", \"table\", \"x\", \"y\",\n",
        "                     \"depth_x_table\", \"depth_x_carat\", \"carat_log\", \"price_log\"] + a_b_features + [\"cut\", \"color\", \"clarity\"]\n",
        "\n",
        "X = df_encoded[selected_features]\n",
        "y = df_encoded[\"outcome\"]\n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define Cross-Validation for More Robust Optuna Optimization\n",
        "cv = KFold(n_splits=17, shuffle=True, random_state=42)\n",
        "\n",
        "trial_18_params = {\n",
        "    \"iterations\": 4284,\n",
        "    \"depth\": 3,\n",
        "    \"learning_rate\": 0.017181970020733888,\n",
        "    \"l2_leaf_reg\": 1.1871493461339557,\n",
        "    \"border_count\": 173,\n",
        "    \"random_strength\": 1.5232946917610097,\n",
        "    \"task_type\": \"GPU\",  # Use GPU acceleration\n",
        "    \"loss_function\": \"RMSE\",\n",
        "    \"random_seed\": 42,  # Fix randomness\n",
        "    \"verbose\": 100,\n",
        "    \"use_best_model\": True  # Use best iteration from training\n",
        "}\n",
        "\n",
        "# Use Cross-Validation (Same as Optuna)\n",
        "cv = KFold(n_splits=17, shuffle=True, random_state=42)\n",
        "r2_scores = []\n",
        "\n",
        "for train_idx, test_idx in cv.split(X):\n",
        "    X_train_cv, X_test_cv = X.iloc[train_idx], X.iloc[test_idx]\n",
        "    y_train_cv, y_test_cv = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "    # Train Model\n",
        "    model = CatBoostRegressor(**trial_18_params)\n",
        "    model.fit(X_train_cv, y_train_cv, eval_set=(X_test_cv, y_test_cv), verbose=0)\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred_cv = model.predict(X_test_cv)\n",
        "    r2_scores.append(r2_score(y_test_cv, y_pred_cv))\n",
        "\n",
        "# Compute Final Cross-Validation R²\n",
        "final_cv_r2 = np.mean(r2_scores)\n",
        "print(f\"✅ Cross-Validated Model R² Score: {final_cv_r2:.5f} \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeDchScQUbIB"
      },
      "source": [
        "make predictions on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "JQBWpCtmUaWS",
        "outputId": "e7bb232f-a860-49cc-c6aa-9d6b72e2d599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 22 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   carat          1000 non-null   float64\n",
            " 1   depth          1000 non-null   float64\n",
            " 2   table          1000 non-null   float64\n",
            " 3   x              1000 non-null   float64\n",
            " 4   y              1000 non-null   float64\n",
            " 5   depth_x_table  1000 non-null   float64\n",
            " 6   depth_x_carat  1000 non-null   float64\n",
            " 7   carat_log      1000 non-null   float64\n",
            " 8   price_log      1000 non-null   float64\n",
            " 9   a1             1000 non-null   float64\n",
            " 10  a2             1000 non-null   float64\n",
            " 11  a3             1000 non-null   float64\n",
            " 12  a4             1000 non-null   float64\n",
            " 13  a5             1000 non-null   float64\n",
            " 14  b1             1000 non-null   float64\n",
            " 15  b2             1000 non-null   float64\n",
            " 16  b3             1000 non-null   float64\n",
            " 17  b4             1000 non-null   float64\n",
            " 18  b5             1000 non-null   float64\n",
            " 19  cut            1000 non-null   int64  \n",
            " 20  color          1000 non-null   int64  \n",
            " 21  clarity        1000 non-null   int64  \n",
            "dtypes: float64(19), int64(3)\n",
            "memory usage: 172.0 KB\n",
            "None\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_74da5047-9393-4175-bbe6-7574bcfd1eff\", \"CW1_submission_k21172604.csv\", 19118)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load test set\n",
        "'''\n",
        "uncomment to load test data from google drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "test_file_path = \"/content/drive/My Drive/MLCW1/CW1_test.csv\"\n",
        "'''\n",
        "test_file_path = \"/data/CW1_train.csv\"\n",
        "\n",
        "X_test = pd.read_csv(test_file_path)\n",
        "\n",
        "# Apply the same categorical encoding\n",
        "X_test[\"cut\"] = X_test[\"cut\"].map(cut_mapping)\n",
        "X_test[\"color\"] = X_test[\"color\"].map(color_mapping)\n",
        "X_test[\"clarity\"] = X_test[\"clarity\"].map(clarity_mapping)\n",
        "\n",
        "# Apply the same feature engineering\n",
        "X_test[\"carat_log\"] = np.log1p(X_test[\"carat\"])\n",
        "X_test[\"price_log\"] = np.log1p(X_test[\"price\"])  # If available\n",
        "X_test[\"depth_x_table\"] = X_test[\"depth\"] * X_test[\"table\"]\n",
        "X_test[\"depth_x_carat\"] = X_test[\"depth\"] * X_test[\"carat\"]\n",
        "\n",
        "# Ensure feature alignment (order & missing columns)\n",
        "X_test = X_test[selected_features]  # Ensure same features as training\n",
        "print(X_test.info())\n",
        "# Predict test outcomes\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Save predictions in required format\n",
        "submission = pd.DataFrame({'yhat': predictions})\n",
        "submission_filename = \"/content/CW1_submission_k21172604.csv\"  # Replace KNUMBER with your real K-number\n",
        "submission.to_csv(submission_filename, index=False)\n",
        "\n",
        "# Download submission file\n",
        "from google.colab import files\n",
        "files.download(submission_filename)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
